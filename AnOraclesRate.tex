\documentclass{article}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{xcolor}

\newcommand{\art}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\aadit}[1]{\begingroup\color{orange}#1\endgroup}
\newcommand{\fred}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\alexei}[1]{\begingroup\color{green}#1\endgroup}

% Lets make it look like writing on a blackboards
% not a 1970s typewriter!
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\e}{\mathbb{E}}
\newcommand{\var}{\mathrm{Var}}

% commands in lower case give less carpal trouble
\newcommand{\mc}{\mathrm{MC}}
\newcommand{\rqmc}{\mathrm{RQMC}}
\newcommand{\runif}{\mathbb{U}}
\newcommand{\rd}{\,\mathrm{d}}
\begin{document}

\section{Asymptotically best budget allocation}

In this section, we consider how an oracle would choose
to allocate the budget between the number $R$ of replications
and the RQMC sample size $n$ of each replicate, subject to
a constraint that $Rn=N$ total function evaluations.  The
oracle in question actually knows exactly how the RQMC
variance decays as $n$ increases.  We will see that
when RQMC is no better than MC, then $n=1$ is best.
On the other hand, when RQMC is {\sl most} effective we should 
also see {\sl very small} $n$ do best.

Suppose that $Y_1,\dots,Y_m$ are independent and identically
distributed random variables with $\Pr(0\le Y_i\le 1)=1$.
Then for $0<\delta<1$,
Bennett's inequality from Maurer and Pontil \cite{maurer2009empirical} shows that
there is probability at least $1-\delta$  that
\begin{align}\label{eq:upperbound}
\e(Y) -   \frac1m\sum_{i=1}^mY_i \le \sqrt{\frac{2\sigma^2\log(1/\delta)}m}
+ \frac{\log(1/\delta)}{3m}.
\end{align}
The oracle can use this to get an interval whose width is
twice the right hand side of the upper bound in~\eqref{eq:upperbound}.
We will look at what choices of $n$ and $R$ minimize this bound for fixed $N$ and $\delta$.

In RQMC we take $m=R$ replicates of $n$ RQMC points.
So the width of the two sided interval is 
\begin{align}\label{eq:thewidth}
\frac{2\sigma_n}{\sqrt{R}}\sqrt{2\log(1/\delta)}  + \frac{2\log(1/\delta)}{3R}
\end{align}
where $\sigma^2_n$ is the RQMC variance using $n$ sample  points.

\aadit{Considering that EB is for IID, is it valid to replace $\sigma^2$ with $\sigma^2_n$? Since it is for IID, could the variance be for the $R$ samples instead? Then, variance could be affected by both $n$ (since $n$ is responsible in getting a value for each $R$) and $R$? - Aadit}
\art{Yes, because we are using $R$ IID samples of $n$ RQMC point sets.  Each RQMC point set gives us one estimate of $\mu$. We do need to do IID re-randomizations of the RQMC points.  If we took $R$ consecutive batches of $n$ points out of one set of $nR$ RQMC points it would not be IID.}

Suppose that $\sigma_n = An^{-\theta}$.  For smooth integrands
and $d=1$, we have $\theta=3/2$ and for smooth integrands with $d>1$, we do better than $3/2-\epsilon$ asymptotically for any $\epsilon>0$, so we use $\theta=3/2$ as an example for RQMC doing very well. If RQMC is only as good as MC, then we would have $\theta=1/2$. Some scrambled digital nets and scrambled Halton methods have variance $o(1/n)$ whenever the MC variance is finite. Therefore $\theta=1/2$ is more pessimistic than realistic and we can use it as a lower bound. For integrands of bounded
variation in the sense of Hardy and Krause, that are not smooth, $\theta<1-\epsilon$ for any $\epsilon>0$ is reasonable, so we use $\theta=1$ for that middle case.  We thus have three interesting values of $\theta$ to consider: $1/2$, $1$ and $3/2$.  Empirical measurements that regress log standard deviation on $\log(n)$ usually show rates between $1/2$ and $3/2$.  They don't necessarily show an asymptotically valid convergence rate, presumably because $n$ is not yet large enough for that.  A rate between $1/2$ and $3/2$ may nonetheless provide a better guide to actual performance than the asymptotic rates. From this point of view, we could find the whole range $1/2\le \theta\le3/2$ useful to consider.

Recall that the budget $N=nR$ is fixed as is $\delta$.
Then the width  of the oracle's window is
\begin{align}\label{eq:oraclewidth}
\frac{2An^{-\theta}}{\sqrt{N/n}}\sqrt{2\log(1/\delta)}  + \frac{2\log(1/\delta)}{3N/n}
=\frac{2A}{\sqrt{N}}n^{1/2-\theta}\sqrt{2\log(1/\delta)}  + \frac{2n\log(1/\delta)}{3N}.
\end{align}
We see immediately that when $\theta = 1/2$, the best $n$ is $n=1$. In other words, if all we are getting is the Monte Carlo rate of convergence then we should expect no improvement from switching to RQMC.  This holds even if RQMC attains the same variance rate as MC but with a favorable constant.  Interestingly, taking $n=1$ in that case would be the same as using plain MC and so there would be no benefit to the oracle's confidence window width from having that variance reduction.  This also means that standard Monte Carlo variance reduction techniques would not be helpful.  We only benefit from a better convergence rate, not a better constant.

For $\theta>1/2$, the oracle's interval width in~\eqref{eq:oraclewidth} is a convex function of $n$ with a unique minimum over $n\in(0,\infty)$ at some value $\tilde n$ which is not necessarily an integer.  
If $\tilde n<1$, then $n=1$ is best.  If $\tilde n$ is a positive
integer then $n=\tilde n$ is best. For noninteger $\tilde n >1$,
the best $n$ is either $\lfloor \tilde n\rfloor$
or  $\lceil \tilde n\rceil$.  We will ignore the fact that the best $n$ is not
necessarily an integer, so of course it is not necessarily a power of 2 (as would be best for scrambled Sobol' points). We just study how the minimizing $n$ changes with $N$.  From here on, we denote the minimizer by $n$ not $\tilde n$.

For $\theta>1/2$, the derivative of the interval width with respect to $n$ is
\begin{align*}
(1/2-\theta)\frac{A}{\sqrt{N}}n^{-1/2-\theta}\sqrt{2\log(1/\delta)}  + \frac{\log(1/\delta)}{3N}.
\end{align*}
This vanishes at 
\begin{align*}
n^{-\theta-1/2} = 
\frac{\frac{\log(1/\delta)}{3N}}
{(\theta-1/2)\frac{A}{\sqrt{N}}
\sqrt{2\log(1/\delta)}}
\end{align*}
and so the optimal choice is
\begin{align}\label{eq:goodn}
n
& = 
\left(\frac
{(\theta-1/2)\frac{A}{\sqrt{N}}
\sqrt{2\log(1/\delta)}}{\frac{\log(1/\delta)}{3N}}\right)^{1/(\theta+1/2)}\notag\\
& = 
\left(\frac{3(\theta-1/2)A                                                                               \sqrt{2N}}{\sqrt{\log(1/\delta)}}\right)^{1/(\theta+1/2)}\\
  &\propto N^{1/(2\theta+1)}.\notag
\end{align}

For $\theta=3/2$ we get $n = O(N^{1/4})$
while for $\theta=1$, we get $n=O(N^{1/3})$.
Note that with a better rate for $\sigma^2_n$
we take smaller $n$. 
We can understand this in terms of equation~\eqref{eq:thewidth}.
The first term there grows smaller as either $n$ or $R$ increases
while the second term responds only to $R$.  When RQMC is extremely
effective the second term dominates and the oracle then increases $R$.

If the oracle picks smaller $n$ for larger $\theta$ then we might
wonder why it picks $n=1$ for the smallest value, $\theta=1/2$. 
This stems from the factor $\theta-1/2$ in the constant of proportionality.
For fixed $A$, $N$ and $\delta$ we could maximize~\eqref{eq:goodn} over $\theta$
to see which rate gives the largest $n$.

\subsection*{Width reduction from RQMC}

Here we look at how much narrower the empirical Bernstein windows
could be when using RQMC instead of MC.
For MC we would take $n=1$
while with RQMC, our oracle would use $n$ from \eqref{eq:goodn}.
The ratio of these widths is
\begin{align*}
\rho &=\frac{\frac{2A}{\sqrt{N}}n^{1/2-\theta}\sqrt{2\log(1/\delta)}  + \frac{2n\log(1/\delta)}{3N}}{
\frac{2A}{\sqrt{N}}\sqrt{2\log(1/\delta)}  + \frac{2\log(1/\delta)}{3N}}\\
&=\frac{3A\sqrt{N}n^{1/2-\theta}\sqrt{2\log(1/\delta)}  + n\log(1/\delta)}{
{3A}{\sqrt{N}}\sqrt{2\log(1/\delta)}  + \log(1/\delta)}.
\end{align*}


Now
\begin{align*}
n^{1/2-\theta} 
&= \left(\frac
{3(\theta-1/2)A
  \sqrt{2N}}{\sqrt{\log(1/\delta)}}\right)^{(1/2-\theta)/(\theta+1/2)}\\
&= O( N^{(1/2-\theta)/(2\theta+1)}),
\end{align*}
as $N\to\infty$. So for $\theta>1/2$, the width ratio is
\begin{align*}
\rho&=\Bigl(
\Theta(N^{1/2+(1/2-\theta)/(2\theta+1)})
+ \Theta( N^{1/(2\theta+1)})
\Bigr)\Bigm/
\Theta(N^{1/2})\\
&=\Theta( N^{(1-2\theta)/(4\theta+2)}).
\end{align*}

For $\theta=1$, corresponding to a plain Koksma-Hlawka rate
we get a ratio of $\Theta(N^{-1/6})$.
For $\theta=3/2$, corresponding to a rate for smooth integrands
we get a more favorable width ratio of $\Theta(N^{-1/4})$.
The MC widths decay proportionally to $N^{1/2}$, so the
RQMC widths decay proportionally to $N^{3/4}$.

\section{One dimensional examples}

Here we consider some one dimensional functions where we know exactly what the RQMC variance is for given $n$.  For these we can compute the best $n$ for an empirical Bernstein interval.  For other one dimensional functions we can compute the asymptotic variance of an RQMC estimate. For a smooth integrand with $\theta=3/2$, the best $n$ grows proportionally to $N^{1/4}$ while for a nonsmooth integrand of bounded variation the best $n$ grows proportionally to $N^{1/3}$.  These are not very different.  For example $N^{1/3}/N^{1/4}=N^{1/12}$, and  so unless the implied constants in the rates differ enormously between two cases we will see similar $n$.

\subsection{Smooth $f$}
For $Y=f(x)=x$ and $x\sim \runif[0,1]$, we can work out how the oracle's
choice would behave.  We find that the optimal $n$ does indeed grow
very slowly with $N$ and that the resulting window lengths
decrease proportionally to $N^{-3/4}$.


The random variable $Y$ has variance $1/12$.
When $n$ is a power of two, then a nested uniform scramble for this setting is
the same as stratified sampling, taking one value independently
within each of $n$ equal length intervals. Then the RQMC variance is
$$
\frac{1}{12n^3}
$$
so $A=1/12$ and $\theta=3/2$.  
%For scrambled Sobol' this rate requires $n$ to be a power of $2$.  
%Otherwise I think we just
%get $O(n^{-2})$ with a constant that depends on the ratio
%between $n$ and the nearest power of $2$.
The MC variance is $1/(12n)$.

\art{Because $2\sqrt{12}=1\sqrt{3}$,} the oracle will get an interval of width
\begin{align*}
w_{\rqmc}&=\art{\frac{1}{\sqrt{3N}}}n^{-1}\sqrt{2\log(1/\delta)}  + \frac{2n\log(1/\delta)}{3N}.
\end{align*}
For $N = 2^m$ and $m=0,1,\dots,30$, we can work out the
interval width for any value of $n$ that is a power of $2$
between $1$ and $N$ inclusive. Table~\ref{tab:forx} shows
how the width minimizing value of $n$ grows with $N$.
For example, we have $n<4$ until $N=2048$ and we only choose
$n=16$ once $N$ is $2^{19}$.  As expected, we see $n$ double
once when $N$ doubles four times, once $N\ge128$. The width scales as $N^{3/4}$
as expected.

\begin{table}\centering
\begin{tabular}{rrrrr}
\toprule
$\log_2(N)$&         $N$ & $n$    &    $w$ &$N^{3/4}w$\\
\midrule 
 0&         1 &  1 &3.4e$+$00  &3.410362\\
 3&         8 &  2& 7.5e$-$01  &3.563392\\
 7&       128 &  4& 9.4e$-$02  &3.563392\\
11&      2048 &  8& 1.2e$-$02  &3.563392\\
15&     32768 & 16& 1.5e$-$03  &3.563392\\
19&    524288 & 32& 1.8e$-$04  &3.563392\\
23&   8388608 & 64& 2.3e$-$05  &3.563392\\
27& 134217728 &128& 2.9e$-$06  &3.563392\\
\bottomrule
\end{tabular}
\caption{\label{tab:forx} For $f(x)=x$, this table shows optimal
$n$ for each of several $N$, along with the empirical Bernstein
width $w$ and $N^{3/4}w$. We only include value of $N$ for which
$n$ has increased. It uses $\delta = 0.05$.
\art{The numbers above are corrected from an earlier version. The values of $n$ grow slowly but perhaps faster than the empirical best $n$ do.}
}
\end{table}



This function has standardized fourth moment
$$
\kappa = \e((Y-1/2)^4)/\var(Y)^2 = 9/5
$$
which we can use in a prior method from GAIL.

For other smooth functions on $[0,1]$, we can work out that
the RQMC variance is approximately
$$
\frac1{12n^3}\int_0^1 f'(x)^2\rd x
$$
so we take $A = \int_0^1f'(x)^2\rd x/12$ along with $\theta=3/2$.
For $f(x) = x\exp(x-1)$, we get $f'(x) = (x+1)\exp(x-1)$, so
$$
\art{A^2} =\frac1{12}\int_0^1 (x+1)^2\exp(2x-2)\rd x=\frac1{48}\Bigl(5-\frac{1}{e^2}\Bigr)
$$
(from WolframAlpha). With this value of $A$, we get the same values of $n$ for $N=2^m$ and $0\le m\le 30$ as we did for $f(x)=x$.


If $f$ is highly oscillatory then we find that larger $n$
give better oracle widths than before.  Consider
$$
f(x) = \frac{1+\sin(2\pi\omega x)}2.
$$
Then $f'(x)^2=\pi^2\omega^2\cos(2\pi\omega x)^2$ and 
$$
A = \frac{\pi^2\omega^2}{12}\int_0^1\cos(2\pi\omega x)^2\rd x
= \frac{\pi^2\omega^2}{96}\Bigl( \frac{\sin(4\pi\omega)}{\pi\omega}+4\Bigr)
$$
(again via WolframAlpha). Taking $\omega$ to be a positive integer, we get
$A=\pi^2\omega^2/24$.
If $\omega =5$, then $f$ goes through $5$ complete sinusoidal periods
in $[0,1]$. We get $A=25\pi^2/24\doteq10.3$ and (some R output is)

For this highly oscillatory case we see $n=N$ for small $N$ and
then eventual slow growth in $n$ with $N$.

\subsection{Nonsmooth $f$}

We can work out the RQMC variance for the function $f(x)=1\{x\le 1/3\}$ for scrambled Sobol' points
when $n$ is a power of $2$. The binary expansion of $1/3$
is $0.01010101\cdots$.  When $n$ is a power of $2$ we will find that $f$ is constant within $n-1$ of the intervals $[(i-1)/n,i/n)$ and so $n-1$ of the function values will have variance zero (after ordering them). The value in the remaining interval will be $1$ with probability $p_n$ and $0$ otherwise.  The value of $p_n$ is either $1/3$ or $2/3$. Either way, the RQMC variance will be $(1/3)(2/3)/n^2$ so $\sigma=An^{-\theta}$ for $\theta=1$ and $A=\sqrt{2}/3$.  Table~\ref{tab:forxunderonethird} shows results for this integrand comparable
to those in Table~\ref{tab:forx} for $f(x)=x$.

We can also find (via Wikipedia) that for $Y=f(x)$
and $x\sim\runif[0,1]$
$$
\frac{\e((Y-\mu)^4)}{\e((Y-\mu)^2)^2} = \frac32.
$$

\begin{table}[t]
\centering
\begin{tabular}{rrrrr}
\toprule
$\log_2(N)$&         $N$ & $n$    &    $w$ &$N^{1/6}w$\\
\midrule 
  0&         1&   1& 4.3e$+$00 &4.304913\\
  4&        16&   2& 6.6e$-$01 &4.175513\\
  7&       128&   4& 1.6e$-$01 &4.175513\\
 10&      1024&   8& 4.1e$-$02 &4.175513\\
 13&      8192&  16& 1.0e$-$02 &4.175513\\
 16&     65536&  32& 2.6e$-$03 &4.175513\\
 19&   524288 & 64& 6.4e$-$04 &4.175513\\
 22&  4194304& 128& 1.6e$-$04 &4.175513\\
 25& 33554432& 256& 4.0e$-$05 &4.175513\\
 28& 268435456& 512& 1.0e$-$05 &4.175513\\
\bottomrule
\end{tabular}
\caption{\label{tab:forxunderonethird} For $f(x)=1\{x\le 1/3\}$, this table shows optimal
$n$ for each of several $N$, along with the empirical Bernstein
width $w$ and $N^{1/6}w$. We only include value of $N$ for which
$n$ has increased. It uses $\delta = 0.05$.
}
\end{table}


\begin{table}
    \centering
    \begin{tabular}{rrrr}
    \toprule
    $n$& $N_{\text{x}}$ & $N_{x<1/3}$ & $N_x/N_{x<1/3}$\\
\midrule
2&8& 16 & 2\\
4&128& 128 & 1\\
8&2048& 1024 & 2\\
16 &32768& 8192 & 4\\
32 &524288& 65536 & 8\\
64 &8388608& 524288 &16\\
\bottomrule
    \end{tabular}
    \caption{
This table records the smallest power of $2$
at which $n$ first becomes the optimal RQMC
sample size.  The column $N_x$ is for $f(x)=x$
with RQMC variance $1/(12n^3)$. The column $N_{x<1/3}$ is
for $f(x) = 1\{x<1/3\}$ with RQMC variance $2/(9n^2)$.
    Caption}
    \label{tab:my_label}
\end{table}

\bibliographystyle{plain}
\bibliography{FJH25}
\end{document}
